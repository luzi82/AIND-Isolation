<style>
.lb{page-break-inside:avoid;}
</style>

<h1>Heuristic Analysis</h1>

<div class="lb">

<h2>tournament.py modification</h2>

<p>The file <code>tournament2.py</code> is copy of <code>tournament.py</code>, and is changed in following ways:</p>

<ul>
<li>Increase NUM_MATCHES from 5 to 25, so more matches will be done to improve banchmark accuracy.</li>
<li>Remove <code>ID_Improved</code> from test_agents, since <code>ID_Improved</code> is only needed to run once to get it's performance value.</li>
</ul>

</div>
<div class="lb">

<h2>Heuristic functions</h2>

<h3>ID_Improved (given)</h3>

<p><code>ID_Improved</code> calculate the number of available move of 2 players, and minus them to get the score.</p>

<p>The <code>tournament2.py</code> result is as follow:</p>

<pre><code>*************************
 Evaluating: ID_Improved 
*************************

Playing Matches:
----------
  Match 1: ID_Improved vs   Random      Result: 89 to 11
  Match 2: ID_Improved vs   MM_Null     Result: 73 to 27
  Match 3: ID_Improved vs   MM_Open     Result: 57 to 43
  Match 4: ID_Improved vs MM_Improved   Result: 54 to 46
  Match 5: ID_Improved vs   AB_Null     Result: 64 to 36
  Match 6: ID_Improved vs   AB_Open     Result: 64 to 36
  Match 7: ID_Improved vs AB_Improved   Result: 57 to 43


Results:
----------
ID_Improved         65.43%
</code></pre>

<table border=1>
<tr><th></th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr><th>ID_Improved</th><td>89</td><td>73</td><td>57</td><td>54</td><td>64</td><td>64</td><td>57</td><td>65.43%</td></tr>
</table>

</div>
<div class="lb">

<h3>custom_score_0 (Improved ID_Improved)</h3>

<p>The <code>custom_score_0</code> put n moves forward into consideration.</p>

<p>For example, in a 4x4 game:</p>

<p><img src="img/sample_game.png" alt="" /></p>

<p>We first do breadth first search to find the number of move required to go to each cell, in empty board.</p>

<p>Since the calculation is based on empty board, the result can be cached to save CPU.</p>

<p><img src="img/cs0_move_a.png" alt="" />
<img src="img/cs0_move_b.png" alt="" /></p>

<p>Then, for each cell which require n moves, we score it r<sub>0</sub><sup>n</sup>.</p>

<p>For r<sub>0</sub> = 1/8:</p>

<p><img src="img/cs0_score_a.png" alt="" />
<img src="img/cs0_score_b.png" alt="" /></p>

<p>Finally, we sum up all cell which is not blocked, and subtract each other.</p>

<ul>
<li>Player A: value = 0.316</li>
<li>Player B: value = 0.193</li>
<li>score = 0.316 - 0.193 = 0.123</li>
</ul>

<p>The <code>tournament2.py</code> result is as follow:</p>

<table border=1>
<tr><th>r<sub>0</sub></th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr><th>1/2</th><td>88</td><td>79</td><td>63</td><td>60</td><td>71</td><td>65</td><td>66</td><td>70.29%</td></tr>
<tr><th>1/3</th><td>91</td><td>82</td><td>68</td><td>60</td><td>77</td><td>67</td><td>63</td><td>72.57%</td></tr>
<tr><th>1/4</th><td>90</td><td>83</td><td>67</td><td>67</td><td>82</td><td>69</td><td>59</td><td>73.86%</td></tr>
<tr><th>1/5</th><td>86</td><td>79</td><td>70</td><td>63</td><td>75</td><td>67</td><td>68</td><td>72.57%</td></tr>
<tr style='color:red'><th>1/6</th><td>90</td><td>84</td><td>76</td><td>64</td><td>83</td><td>77</td><td>74</td><td>78.29%</td></tr>
<tr><th>1/7</th><td>87</td><td>79</td><td>74</td><td>74</td><td>77</td><td>75</td><td>72</td><td>76.86%</td></tr>
<tr><th>1/8</th><td>90</td><td>80</td><td>71</td><td>61</td><td>83</td><td>68</td><td>68</td><td>74.43%</td></tr>
<tr><th>1/9</th><td>88</td><td>86</td><td>64</td><td>67</td><td>86</td><td>75</td><td>69</td><td>76.43%</td></tr>
<tr><th>1/10</th><td>90</td><td>87</td><td>74</td><td>68</td><td>85</td><td>75</td><td>68</td><td>78.14%</td></tr>
<tr style="color:blue"><th>ID_Imp</th><td>89</td><td>73</td><td>57</td><td>54</td><td>64</td><td>64</td><td>57</td><td>65.43%</td></tr>
</table>

<p>It is better than <code>ID_Improved</code>.</p>

</div>
<div class="lb">

<h3>custom_score_1 (Neural network)</h3>

<p>The <code>custom_score_1</code> is based on neural network and minimax Q learning.</p>

<p>First, we convert the 7x7 game data into 7x7x3 = 147 boolean value.
The first 7x7 boolean value represent which cell is not blocked.
The second 7x7 boolean value represent the location of active player.
The third 7x7 boolean value represent the location of inactive player.</p>

<p><img src="img/sample_game.png" alt="" /></p>

<p>becomes</p>

<p><img src="img/cs1_data.png" alt="" /></p>

<p>Then we put the values into 3 hidden layers neural network, which represent the score of 8 move.
We apply boolean mask to filter out impossible move.</p>

<p>Score of move a<sub>0</sub> in state s<sub>0</sub>:</p>

<pre><code>Q(s0,a0)
</code></pre>

<p>The score of state s<sub>0</sub> would be:</p>

<pre><code>max( Q(s0,a0) for all a0 )
</code></pre>

<p>The neural network is trained by following equation:</p>

<pre><code>Q(s0,a0) = -1                                   if loss
         = +1                                   if win
         = - gamma * max( Q(s1,a1) for all a1 ) otherwise
</code></pre>

<p>Since the Q function return the score of the active player, and the second move is made by opponent, the right hand side of the equation should be negative.</p>

<p>Step of training:</p>

<ol>
<li>Make 100000 moves</li>
<li>Train upon 1-100000th move</li>
<li>Make 100001st move</li>
<li>Train upon 2-100001th move</li>
<li>Make 100002st move</li>
<li>Train upon 3-100002th move</li>
<li>continue...</li>
</ol>

<div class="lb">

<p>The <code>tournament2.py</code> result is as follow:</p>

<table border=1>
<tr><th>moves</th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr><th>200000</th><td>88</td><td>72</td><td>52</td><td>44</td><td>75</td><td>53</td><td>47</td><td>61.57%</td></tr>
<tr><th>300000</th><td>88</td><td>80</td><td>58</td><td>53</td><td>75</td><td>63</td><td>51</td><td>66.86%</td></tr>
<tr><th>400000</th><td>88</td><td>78</td><td>61</td><td>47</td><td>70</td><td>57</td><td>54</td><td>65.00%</td></tr>
<tr><th>500000</th><td>90</td><td>81</td><td>61</td><td>55</td><td>75</td><td>54</td><td>56</td><td>67.43%</td></tr>
<tr><th>600000</th><td>88</td><td>80</td><td>60</td><td>55</td><td>79</td><td>60</td><td>51</td><td>67.57%</td></tr>
<tr><th>700000</th><td>82</td><td>77</td><td>53</td><td>56</td><td>80</td><td>63</td><td>50</td><td>65.86%</td></tr>
<tr><th>3760000</th><td>90</td><td>75</td><td>51</td><td>54</td><td>74</td><td>55</td><td>45</td><td>63.43%</td></tr>
</table>

</div>

<p>The result is disappointing.  The result does not grow in training.</p>

<p>In order to improve performance, complexity of the neural network should be increase.  For example, apply convolution layer, and add more feature to input data set.  More CPU / GPU time should be required.</p>

<p>Moreover, the trained neural network can be used only in game same as training game.
For games which have difference size, it is necessary to train another neural network.</p>

<p>The <code>custom_score_1</code> require TensorFlow to run.</p>

<h3>custom_score_2 (Distance from center)</h3>

<p>The output is the distance between player location to the center.
Since we are not sure it is better to stay at center or edge, so we make 2 opposite functions to verify.</p>

<ul>
<li>version 2a: Self distance - Opponent distance.  Stay on edge will get higher score.</li>
<li>version 2b: Opponent distance - Self distance.  Stay in center will get higher score.</li>
</ul>

<table border=1>
<tr><th></th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr><th>2a</th><td>82</td><td>73</td><td>60</td><td>48</td><td>64</td><td>60</td><td>49</td><td>62.29%</td></tr>
<tr><th>2b</th><td>87</td><td>65</td><td>62</td><td>49</td><td>72</td><td>56</td><td>59</td><td>64.29%</td></tr>
</table>

<p>The agent is weaker than <code>ID_Improved</code>.</p>

<p>The difference is so small that we cannot tell which strategy is better.
So we reduce the search_depth to 1 to verify.</p>

<table border=1>
<tr><th></th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr><th>2a</th><td>37</td><td>11</td><td>6</td><td>7</td><td>12</td><td>8</td><td>8</td><td>12.71%</td></tr>
<tr><th>2b</th><td>78</td><td>54</td><td>21</td><td>22</td><td>43</td><td>24</td><td>27</td><td>38.43%</td></tr>
</table>

<p>Now we can see in depth 1 search, stay in center is better than stay in edge.  The discovery can be used in building better agent.</p>

</div>
<div class="lb">

<h3>custom_score_3 ( custom_score_0 + custom_score_2 )</h3>

<p><code>custom_score_3</code> combine <code>custom_score_0</code> and <code>custom_score_2b</code> by adding them up.</p>

<pre><code>custom_score_3b = custom_score_0(r=1/6) + r3 * custom_score_2b
</code></pre>

<table border=1>
<tr><th>r<sub>3</sub></th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr style='color:blue'><th>cs2a</th><td>82</td><td>73</td><td>60</td><td>48</td><td>64</td><td>60</td><td>49</td><td>62.29%</td></tr>
<tr><th>r=-0.8</th><td>83</td><td>82</td><td>60</td><td>58</td><td>75</td><td>61</td><td>56</td><td>67.86%</td></tr>
<tr><th>r=-0.6</th><td>89</td><td>80</td><td>65</td><td>57</td><td>77</td><td>57</td><td>54</td><td>68.43%</td></tr>
<tr><th>r=-0.4</th><td>90</td><td>80</td><td>70</td><td>59</td><td>78</td><td>69</td><td>60</td><td>72.29%</td></tr>
<tr><th>r=-0.2</th><td>88</td><td>89</td><td>71</td><td>58</td><td>82</td><td>63</td><td>65</td><td>73.71%</td></tr>
<tr style='color:blue'><th>cs0</th><td>89</td><td>87</td><td>75</td><td>72</td><td>79</td><td>71</td><td>74</td><td>78.14%</td></tr>
<tr><th>r=0.2</th><td>92</td><td>89</td><td>70</td><td>66</td><td>77</td><td>71</td><td>67</td><td>76.00%</td></tr>
<tr><th>r=0.4</th><td>86</td><td>80</td><td>65</td><td>67</td><td>77</td><td>77</td><td>69</td><td>74.43%</td></tr>
<tr><th>r=0.6</th><td>89</td><td>77</td><td>72</td><td>61</td><td>76</td><td>70</td><td>65</td><td>72.86%</td></tr>
<tr><th>r=0.8</th><td>90</td><td>89</td><td>74</td><td>64</td><td>77</td><td>72</td><td>72</td><td>76.86%</td></tr>
<tr style='color:blue'><th>cs2b</th><td>87</td><td>65</td><td>62</td><td>49</td><td>72</td><td>56</td><td>59</td><td>64.29%</td></tr>
</table>

<p>It show both <code>custom_score_2a</code> and <code>custom_score_2b</code> does not improve <code>custom_score_0</code>.</p>

<h3>custom_score_4 (Simulation)</h3>

<p><code>custom_score_4</code> run simulation play to end game, and output the win/loss of the result.</p>

<p>In simulation, the game will choose the move closest to the board center.  We choose this feature since it is less CPU consumption and effective.</p>

<p>For the game which win in n step, the function would output r<sub>4</sub><sup>n</sup> (0 &lt; r<sub>4</sub> &lt; 1).
For the game which loss in n step, the function would output -r<sub>4</sub><sup>n</sup>.
So the AI would prefer early win than later win, and prefer later loss than early loss.</p>

<p>The runtime and performance of this function depends on number of blank cell in the board.
With more blank cell, simulation require more time, and the result is less accurate.
As step count increase, +/-r<sub>4</sub><sup>n</sup> would be close to zero.
So we may put a cutdown to save CPU.  But now we just simulate to endgame.</p>

<p>It is meaningless to tune r<sub>4</sub>.  We just need to ensure 0 &lt; r<sub>4</sub> &lt; 1.</p>

<table border=1>
<tr><th>type</th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr><th>cs4</th><td>93</td><td>77</td><td>67</td><td>63</td><td>68</td><td>68</td><td>59</td><td>70.71%</td></tr>
</table>

<p>It's strength is close to <code>ID_Improved</code>, and weaker than <code>custom_score_0</code>, even though it consume high CPU.</p>

</div>
<div class="lb">

<h3>custom_score_5 (custom_score_0 + custom_score_4)</h3>

<p><code>custom_score_5</code> combine <code>custom_score_0</code> and <code>custom_score_4</code> by adding them together.</p>

<pre><code>custom_score_5 = (1-r5) * custom_score_0 + r5 * custom_score_4
</code></pre>

<p>To get the best performance of the function, we need to tune r<sub>0</sub>, r<sub>4</sub> and r<sub>5</sub> together.
For simplicity we take r<sub>0</sub> = 1/6, r<sub>4</sub> = 0.99, and tune r<sub>5</sub>.</p>

<p>Result: (r<sub>0</sub> = 1/6, r<sub>4</sub> = 0.99)</p>

<table border=1>
<tr><th>r<sub>5</sub></th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Improved</th><th>AB_Null</th><th>AB_Open</th><th>AB_Improved</th><th>Result</th></tr>
<tr style='color:blue'><th>cs0</th><td>90</td><td>84</td><td>76</td><td>64</td><td>83</td><td>77</td><td>74</td><td>78.29%</td></tr>
<tr><th>0.1</th><td>93</td><td>88</td><td>78</td><td>75</td><td>83</td><td>76</td><td>73</td><td>80.86%</td></tr>
<tr><th>0.2</th><td>95</td><td>90</td><td>74</td><td>77</td><td>87</td><td>77</td><td>72</td><td>81.71%</td></tr>
<tr><th>0.3</th><td>90</td><td>87</td><td>75</td><td>76</td><td>86</td><td>78</td><td>73</td><td>80.71%</td></tr>
<tr><th>0.4</th><td>93</td><td>89</td><td>73</td><td>69</td><td>90</td><td>73</td><td>77</td><td>80.57%</td></tr>
<tr style="color:red"><th>0.5</th><td>94</td><td>85</td><td>78</td><td>77</td><td>91</td><td>80</td><td>71</td><td>82.29%</td></tr>
<tr><th>0.6</th><td>98</td><td>90</td><td>78</td><td>73</td><td>82</td><td>84</td><td>68</td><td>81.86%</td></tr>
<tr><th>0.7</th><td>90</td><td>91</td><td>72</td><td>70</td><td>89</td><td>79</td><td>72</td><td>80.43%</td></tr>
<tr><th>0.8</th><td>91</td><td>94</td><td>73</td><td>71</td><td>87</td><td>77</td><td>66</td><td>79.86%</td></tr>
<tr><th>0.9</th><td>94</td><td>90</td><td>75</td><td>71</td><td>87</td><td>71</td><td>74</td><td>80.29%</td></tr>
<tr style='color:blue'><th>cs4</th><td>93</td><td>77</td><td>67</td><td>63</td><td>68</td><td>68</td><td>59</td><td>70.71%</td></tr>
</table>

<p>The performance of <code>custom_score_5</code> is better than <code>custom_score_0</code> and <code>custom_score_4</code>.
r<sub>0</sub>, r<sub>4</sub>, and r<sub>5</sub> can be further tuned to achieve better performance.</p>

<h2>Conclusion</h2>

<p>Here is the summary of the heuristic functions:</p>

<table border=1>
<tr><th>type</th><th>Random</th><th>MM_Null</th><th>MM_Open</th><th>MM_Imp</th><th>AB_Null</th><th>AB_Open</th><th>AB_Imp</th><th>Result</th></tr>
<tr style='color:blue'><th>ID_Improved</th><td>89</td><td>73</td><td>57</td><td>54</td><td>64</td><td>64</td><td>57</td><td>65.43%</td></tr>
<tr><th>cs0</th><td>90</td><td>84</td><td>76</td><td>64</td><td>83</td><td>77</td><td>74</td><td>78.29%</td></tr>
<tr><th>cs1</th><td>90</td><td>75</td><td>51</td><td>54</td><td>74</td><td>55</td><td>45</td><td>63.43%</td></tr>
<tr><th>cs2</th><td>87</td><td>65</td><td>62</td><td>49</td><td>72</td><td>56</td><td>59</td><td>64.29%</td></tr>
<tr><th>cs3</th><td>90</td><td>89</td><td>74</td><td>64</td><td>77</td><td>72</td><td>72</td><td>76.86%</td></tr>
<tr><th>cs4</th><td>93</td><td>77</td><td>67</td><td>63</td><td>68</td><td>68</td><td>59</td><td>70.71%</td></tr>
<tr style="color:red"><th>cs5</th><td>94</td><td>85</td><td>78</td><td>77</td><td>91</td><td>80</td><td>71</td><td>82.29%</td></tr>
</table>

<p>We recommend <code>custom_score_5</code>:</p>

<ul>
<li>It achieve best result when matching with random opponent, with chance 94%.</li>
<li>It achieve good result when matching with intelligent opponents such as <code>open_move_score</code> and <code>improved_score</code>, with higher than 70% chance.  Although the winning rate versus <code>AB_Imp</code> is slightly lower, it perform best when versus <code>MM_Open</code>, <code>MM_Improve</code> and <code>AB_Open</code>.</li>
<li>It's result % is the best among all other custom score.</li>
</ul>

<p>In CPU limited environment, we recommend <code>custom_score_0</code>, as the evaluate function can run in constant time in larger board.</p>

<p>In extreme limited environment, <code>custom_score_2b</code> would be a choice as it does not require much calculation.</p>

</div>
<div class="lb">

<h3>tournament.py output</h3>

<pre><code>This script evaluates the performance of the custom heuristic function by
comparing the strength of an agent using iterative deepening (ID) search with
alpha-beta pruning against the strength rating of agents using other heuristic
functions.  The `ID_Improved` agent provides a baseline by measuring the
performance of a basic agent using Iterative Deepening and the "improved"
heuristic (from lecture) on your hardware.  The `Student` agent then measures
the performance of Iterative Deepening and the custom heuristic against the
same opponents.


*************************
 Evaluating: ID_Improved 
*************************

Playing Matches:
----------
  Match 1: ID_Improved vs   Random      Result: 17 to 3
  Match 2: ID_Improved vs   MM_Null     Result: 14 to 6
  Match 3: ID_Improved vs   MM_Open     Result: 11 to 9
  Match 4: ID_Improved vs MM_Improved   Result: 12 to 8
  Match 5: ID_Improved vs   AB_Null     Result: 15 to 5
  Match 6: ID_Improved vs   AB_Open     Result: 12 to 8
  Match 7: ID_Improved vs AB_Improved   Result: 12 to 8


Results:
----------
ID_Improved         66.43%

*************************
   Evaluating: Student   
*************************

Playing Matches:
----------
  Match 1:   Student   vs   Random      Result: 18 to 2
  Match 2:   Student   vs   MM_Null     Result: 18 to 2
  Match 3:   Student   vs   MM_Open     Result: 16 to 4
  Match 4:   Student   vs MM_Improved   Result: 14 to 6
  Match 5:   Student   vs   AB_Null     Result: 17 to 3
  Match 6:   Student   vs   AB_Open     Result: 15 to 5
  Match 7:   Student   vs AB_Improved   Result: 17 to 3


Results:
----------
Student             82.14%
</code></pre>

</div>
